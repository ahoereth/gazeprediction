{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Saliency-Based Visual Attention</center>\n",
    "\n",
    "<p><small>Sebastian HÃ¶ffner<br />October 31, 2016</small>\n",
    "\n",
    "<p><small><b>Laurent Itti, Christof Koch, Ernst Niebur</b>: A Model of Saliency-Based Visual Attention for Rapid Scene Analysis. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, Vol 20, No 11, pp. 1254&ndash;1259. 1998.\n",
    "\n",
    "<p><br /></p>\n",
    "<p><small>Image credit goes to the paper if not otherwise mentioned. Note that I do not always introduce all notations, but I follow the naming in the paper closely, so please refer to the paper in case you get lost.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "## This cell contains the methods needed and imports, run before we start\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "def to256(image):\n",
    "    return (255. * image / np.max(image)).astype(np.uint8)\n",
    "\n",
    "def imshow(image, conversion=cv2.COLOR_BGR2RGB):\n",
    "    \"\"\"Converts the image from BGR to RGB and plots it. \n",
    "    Returns the image.\"\"\"\n",
    "    if len(image.shape) == 2:\n",
    "        conversion = None\n",
    "    if conversion is None:\n",
    "        plt.imshow(image, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(cv2.cvtColor(image, conversion))\n",
    "    plt.axis('off')\n",
    "    return image\n",
    "    \n",
    "def imshow_pyr(images, name='Pyramid', conversion=cv2.COLOR_BGR2RGB):\n",
    "    \"\"\"Shows a pyramid of 9 images. Returns the pyramid.\"\"\"\n",
    "    plt.figure(name)\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        if len(images[i].shape) == 2:\n",
    "            conversion = None\n",
    "        if conversion is None:\n",
    "            plt.imshow(images[i], interpolation='none', cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(cv2.cvtColor(images[i], conversion), interpolation='none')\n",
    "        plt.title(\"{}x{}\".format(images[i].shape[1], images[i].shape[0]))\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return images\n",
    "    \n",
    "def gauss_pyramid(image):\n",
    "    \"\"\"Calculates a Gaussian pyramid of 9 images\n",
    "    (scales 1:2^0 ... 1:2^8).\"\"\"\n",
    "    pyramid = [image.copy()]\n",
    "    for i in range(8):\n",
    "        pyramid.append(cv2.pyrDown(pyramid[-1]))\n",
    "    return pyramid\n",
    "\n",
    "def intensity(image):\n",
    "    \"\"\"Calculates an intensity image, the average\n",
    "    over all channels per pixel.\"\"\"\n",
    "    return (np.sum(image, 2) / 3.).astype(np.uint8)\n",
    "\n",
    "def hue_from_intensity(image, intensity_image):\n",
    "    \"\"\"Calculates the hue image by dividing by\n",
    "    the intensity. 0 where the intensity is too small \n",
    "    (< 10% of max)\"\"\"\n",
    "    copy_img = image.copy()\n",
    "    copy_int = intensity_image.copy()\n",
    "    copy_int.shape = copy_int.shape + (1,)\n",
    "    idx = np.where(copy_int > np.max(copy_int) * .1)\n",
    "    copy_img[idx] = 1. * copy_img[idx] / copy_int[idx]\n",
    "    copy_img[np.where(copy_int <= np.max(copy_int) * .1)] = 0\n",
    "    return copy_img\n",
    "\n",
    "def channel_or_zeros(c0, c1, c2):\n",
    "    \"\"\"Fills up a color channel with 0 channels to plot it nicely.\n",
    "    Set channels to None to use zeros.\"\"\"\n",
    "    if c0 is not None:\n",
    "        z = np.zeros(c0[:,:,np.newaxis].shape)\n",
    "    elif c1 is not None:\n",
    "        z = np.zeros(c1[:,:,np.newaxis].shape)\n",
    "    elif c2 is not None:\n",
    "        z = np.zeros(c2[:,:,np.newaxis].shape)\n",
    "    \n",
    "    out = np.append(c0[:,:,np.newaxis] if c0 is not None else z, c1[:,:,np.newaxis] if c1 is not None else z, axis=2)\n",
    "    out = np.append(out, c2[:,:,np.newaxis] if c2 is not None else z, axis=2)\n",
    "    return to256(out)\n",
    "    \n",
    "def get_orientations(image):\n",
    "    \"\"\"Returns a list of orientation images.\"\"\"\n",
    "    orientations = []\n",
    "    input_image = image.copy()\n",
    "    for sigma in range(9):\n",
    "        for theta in range(0, 180, 45):\n",
    "            ksize = tuple((np.array(input_image.shape) * .1).astype(np.uint))\n",
    "            kernel = cv2.getGaborKernel(ksize, sigma, theta, 10, float(input_image.shape[0]) / float(input_image.shape[1]))\n",
    "            orientations.append(cv2.filter2D(input_image, -1, kernel))\n",
    "        input_image = cv2.resize(input_image, None, fx=.5, fy=.5)\n",
    "    return orientations\n",
    "\n",
    "def center_surround_diff_intensity(pyramid,  cs=[2, 3, 4], deltas=[3, 4]):\n",
    "    \"\"\"Calculates the center surround intensity differences for a single intensity pyramid.\"\"\"\n",
    "    feature_maps = []\n",
    "    for c in cs:\n",
    "        for d in deltas:\n",
    "            s = c + d\n",
    "            abs_diff = np.abs(pyramid[c] - cv2.resize(pyramid[s], pyramid[c].T.shape))\n",
    "            feature_maps.append(to256(abs_diff))\n",
    "    return feature_maps\n",
    "\n",
    "def center_surround_diff_color(pyramid1, pyramid2,  cs=[2, 3, 4], deltas=[3, 4]):\n",
    "    \"\"\"Calculates the center surround color differences for complex color pyramides.\n",
    "    The difference to intensity is, that two colors are combined such that\n",
    "    $\\ominus(a-b, b-a)$.\"\"\"\n",
    "    feature_maps = []\n",
    "    for c in cs:\n",
    "        for d in deltas:\n",
    "            s = c + d\n",
    "            image_big = pyramid1[c] - pyramid2[c]\n",
    "            image_small = pyramid2[s] - pyramid1[s]\n",
    "            abs_diff = np.abs(image_big - cv2.resize(image_small, image_big.T.shape))\n",
    "            feature_maps.append(to256(abs_diff))\n",
    "    return feature_maps\n",
    "\n",
    "def center_surround_diff_orientation(pyramid,  cs=[2, 3, 4], deltas=[3, 4]):\n",
    "    \"\"\"Calculates the center surround intensity differences for a single intensity pyramid.\"\"\"\n",
    "    feature_maps = []\n",
    "    for c in cs:\n",
    "        for d in deltas:\n",
    "            s = c + d\n",
    "            abs_diff = np.abs(pyramid[c] - pyramid[s])\n",
    "            feature_maps.append(to256(abs_diff))\n",
    "    return feature_maps\n",
    "\n",
    "def normalize(image):\n",
    "    \"\"\"Calculates the global normalization\"\"\"\n",
    "    M = np.max(image)\n",
    "    m = np.array([m for m in image[argrelextrema(image, np.greater)] if m != M])\n",
    "    mean = np.mean(m)\n",
    "    factor = (M - mean) ** 2\n",
    "    return to256(image.copy() * factor)\n",
    "\n",
    "def sum_up(images, target_size=None):\n",
    "    \"\"\"Sums up images. If a target_size is given, they are rescaled\n",
    "    to that first. Converts the images to uint!\"\"\"\n",
    "    def convert(img):\n",
    "        i = img.copy()\n",
    "        if target_size is not None:\n",
    "            iMax = np.max(i)\n",
    "            i = cv2.resize(to256(i), target_size)\n",
    "            i = (1. * i * iMax / 256).astype(np.uint)\n",
    "        return i.astype(np.uint)\n",
    "    im = [convert(image) for image in images]\n",
    "    result = im[0]\n",
    "    for i, image in enumerate(im[1:]):\n",
    "        result += image\n",
    "    return result\n",
    "\n",
    "def combine_colors(RG, BY):\n",
    "    \"\"\"Combines to color pyramides into one color pyradid of \n",
    "    summed colors. Converts the images to uint!\"\"\"\n",
    "    return [RG[i].astype(np.uint) + BY[i].astype(np.uint) for i in range(len(RG))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Saliency: A method for early selection\n",
    "\n",
    "- bottom-up approach\n",
    "- scene-dependent rather than task-dependent (exogenous)\n",
    "- select highly salient regions to filter upon\n",
    "\n",
    "<br />\n",
    "\n",
    "<center><bold><big>Saliency â‡’ \"Where is the fun?!\"</big></bold></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Architecture\n",
    "\n",
    "\n",
    "<img src=\"ittikochniebur_model_architecture.png\" alt=\"Model architecture\" style=\"width: 60%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "image = imshow(cv2.imread('image.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intensity image\n",
    "\n",
    "<img src=\"ittikochnieburg_intensity.png\" alt=\"Intensity\" style=\"width: 200px\" />\n",
    "\n",
    "$$\\text{int} = \\frac{\\text{red} + \\text{green} + \\text{blue}}{3}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "intensity_image = imshow(intensity(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian pyramid: intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intensity_pyramid = imshow_pyr(gauss_pyramid(intensity_image), 'Gaussian Pyramid Intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_ = imshow_pyr(gauss_pyramid(image), 'Gaussian Pyramid Original Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Colors\n",
    "\n",
    "<img src=\"ittikochnieburg_colors.png\" alt=\"Colors\" style=\"width: 200px\" />\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hue image\n",
    "\n",
    "$\\text{hue}_{x,y} = f(\\text{img}, \\text{int}, x, y) = \\begin{cases} \\text{img}_{x,y} \\ /\\  \\text{int}_{x,y} &\\quad if\\ \\text{int}_{x,y} > 0.1 \\cdot  \\max{\\text{int}} \\\\ 0 &\\quad else\\ \\end{cases}$\n",
    "\n",
    "Note the $0.1$: at low luminance we can't perceive them well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "hue_image = imshow(hue_from_intensity(image, intensity_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure('image to hue')\n",
    "plt.subplot(1, 3, 1); imshow(image)\n",
    "plt.subplot(1, 3, 2); imshow(intensity_image)\n",
    "plt.subplot(1, 3, 3); _ = imshow(hue_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hue image to colors\n",
    "\n",
    "- 4 color maps\n",
    "- R, G, B, Y (Following the [Opponent process](https://en.wikipedia.org/wiki/Opponent_process))\n",
    "\n",
    "![Opponent process](https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Opponent_colors.svg/480px-Opponent_colors.svg.png)\n",
    "\n",
    "<small>Image: wikipedia</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "b, g, r = hue_image[:,:,0], hue_image[:,:,1], hue_image[:,:,2]\n",
    "\n",
    "R = to256( r - (g + b) / 2. )\n",
    "G = to256( g - (r + b) / 2. )\n",
    "B = to256( b - (r + g) / 2. )\n",
    "Y = to256( (r + g) / 2. - np.abs(r - g) / 2. - b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure('Color channels')\n",
    "plt.subplot(2, 2, 3); imshow(channel_or_zeros(None, None, R)); plt.title('Red')\n",
    "plt.subplot(2, 2, 1); imshow(channel_or_zeros(None, G, None)); plt.title('Green')\n",
    "plt.subplot(2, 2, 4); imshow(channel_or_zeros(B, None, None)); plt.title('Blue')\n",
    "plt.subplot(2, 2, 2); imshow(channel_or_zeros(None, Y, Y)); _ = plt.title('Yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "R_pyramid = gauss_pyramid(R)\n",
    "G_pyramid = gauss_pyramid(G)\n",
    "B_pyramid = gauss_pyramid(B)\n",
    "Y_pyramid = gauss_pyramid(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_ = imshow_pyr(R_pyramid, 'Gauss R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_ = imshow_pyr(G_pyramid, 'Gauss G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_ = imshow_pyr(B_pyramid, 'Gauss B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "_ = imshow_pyr(Y_pyramid, 'Gauss Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Orientation\n",
    "\n",
    "- Gabor cells\n",
    "- Four different orientations: 0Â°, 45Â°, 90Â°, 135Â°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_orientations(image):\n",
    "    \"\"\"Returns a list of orientation images.\"\"\"\n",
    "    orientations = []\n",
    "    kernels = []\n",
    "    input_image = image.copy()\n",
    "    for sigma in range(9):\n",
    "        for theta in range(0, 180, 45):\n",
    "            ksize = tuple((np.array(input_image.shape) * .25).astype(np.uint))\n",
    "            kernel = cv2.getGaborKernel(ksize, sigma, theta, 10, float(input_image.shape[0]) / float(input_image.shape[1]))\n",
    "            kernels.append(kernel)\n",
    "            orientations.append(cv2.filter2D(input_image, -1, kernel))\n",
    "        input_image = cv2.resize(input_image, None, fx=.5, fy=.5)\n",
    "    return orientations, kernels\n",
    "\n",
    "orientations, kernels = get_orientations(intensity_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure('Gabor cells')        \n",
    "for i, kernel in enumerate(kernels):\n",
    "    plt.subplot(9, 4, i + 1); \n",
    "    imshow(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure('Gabor results (one)')\n",
    "_ = imshow(orientations[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure('Gabor results')\n",
    "for i, img in enumerate(orientations):\n",
    "    plt.subplot(9, 4, i + 1);\n",
    "    imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature maps\n",
    "\n",
    "- 6 for intensity contrast - mammals: dark centers bright surrounds or vice-versa\n",
    "- 12 for color - mammals: excitation by one color, inhibition by opposite color\n",
    "- 24 for orientation - mammals: primary visual cortex has layers to detect orientations\n",
    "- = 42 feature maps\n",
    "\n",
    "<img src=\"ittikochniebur_model_architecture.png\" alt=\"Model architecture\" style=\"width: 60%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Center-surround differences\n",
    "\n",
    "$$\\mathcal{I}(c, s) = \\left|I(c) \\ominus I(s)\\right|$$\n",
    "\n",
    "$$c \\in \\left\\{2, 3, 4\\right\\}, s = c + \\delta, \\delta \\in \\left\\{3, 4\\right\\}$$\n",
    "\n",
    "<br />\n",
    "\n",
    "<center>$a \\ominus b$: <i>Interpolate $b$ to the size of $a$ (the bigger image) and do a point-wise subtraction</i></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "intensity_maps = center_surround_diff_intensity(intensity_pyramid)\n",
    "plt.figure(\"Center surround differences -- Intensity\")\n",
    "for i in range(6):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    imshow(intensity_maps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "RG_maps = center_surround_diff_color(R_pyramid, G_pyramid); idx_RG = [1, 2, 5, 6, 9, 10]\n",
    "BY_maps = center_surround_diff_color(B_pyramid, Y_pyramid); idx_BY = [3, 4, 7, 8, 11, 12]\n",
    "plt.figure(\"Center surround differences -- Color (RG / BY)\")\n",
    "for i in range(6):\n",
    "    plt.subplot(3,4,idx_RG[i])\n",
    "    imshow(RG_maps[i])\n",
    "for i in range(6):\n",
    "    plt.subplot(3,4,idx_BY[i])\n",
    "    imshow(BY_maps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "orientation_maps_0   = center_surround_diff_intensity(orientations[0::4]); idx_0   = [1, 2, 9, 10, 17, 18]\n",
    "orientation_maps_45  = center_surround_diff_intensity(orientations[1::4]); idx_45  = [3, 4, 11, 12, 19, 20]\n",
    "orientation_maps_90  = center_surround_diff_intensity(orientations[2::4]); idx_90  = [5, 6, 13, 14, 21, 22]\n",
    "orientation_maps_135 = center_surround_diff_intensity(orientations[3::4]); idx_135 = [7, 8, 15, 16, 23, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(\"Center surround differences -- Gabor cells\")\n",
    "for i in range(6):\n",
    "    plt.subplot(6,4,idx_0[i]); imshow(orientation_maps_0[i])\n",
    "    plt.subplot(6,4,idx_45[i]); imshow(orientation_maps_45[i])\n",
    "    plt.subplot(6,4,idx_90[i]); imshow(orientation_maps_90[i])\n",
    "    plt.subplot(6,4,idx_135[i]); imshow(orientation_maps_135[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(\"Center surround differences -- Gabor cells 0\")\n",
    "for i in range(6):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    imshow(orientation_maps_0[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(\"Center surround differences -- Gabor cells 45\")\n",
    "for i in range(6):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    imshow(orientation_maps_45[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(\"Center surround differences -- Gabor cells 90\")\n",
    "for i in range(6):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    imshow(orientation_maps_90[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(\"Center surround differences -- Gabor cells 135\")\n",
    "for i in range(6):\n",
    "    plt.subplot(3,2,i+1)\n",
    "    imshow(orientation_maps_135[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Saliency map\n",
    "\n",
    "<img src=\"ittikochniebur_model_architecture.png\" alt=\"Model architecture\" style=\"width: 60%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Normalization\n",
    "\n",
    "- Find maximum $M$ in image\n",
    "- Compute average $\\bar{m}$ of all other local maxima $m_i$\n",
    "- Multiply map by $(M-\\bar{m})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_maps = intensity_maps + \\\n",
    "               RG_maps + BY_maps + \\\n",
    "               orientation_maps_0 + orientation_maps_45 + orientation_maps_90 + orientation_maps_135\n",
    "norm_maps = [normalize(fmap) for fmap in feature_maps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(); \n",
    "for i, m in enumerate(feature_maps): plt.subplot(7,6,i+1); imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(); \n",
    "for i, m in enumerate(norm_maps): plt.subplot(7,6,i+1); imshow(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combination to conspicuity maps\n",
    "\n",
    "- one map per feature type: intensity, color, orientation\n",
    "- on scale 4, which is $\\text{target_size} = \\frac{\\text{size}}{2^{(4-1)}}$\n",
    "- intensity: sum over all scales\n",
    "- color: sum over scales and maps\n",
    "- orientation: sum over scales, then normalize again before summation over orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "target_size = tuple(np.array(image.shape[0:2][::-1]) / (2 ** 3))\n",
    "\n",
    "conspicuity = [ # intensity\n",
    "    normalize( \n",
    "        sum_up(norm_maps[0:6], target_size))]\n",
    "conspicuity += [ # colors: RG, BY\n",
    "    sum_up( \n",
    "        combine_colors(norm_maps[6:12], norm_maps[12:18]), target_size)]\n",
    "conspicuity += [ # orientations\n",
    "    sum_up( # sum orientations\n",
    "        [normalize( # normalize it\n",
    "                sum_up(norm_maps[i:i+6], target_size) # sum pyramid\n",
    "            ) for i in (18, 24, 30, 36)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure('Conspicuity maps')\n",
    "for i, (cmap, t) in enumerate(zip(conspicuity, ('intensity', 'color', 'orientation'))):\n",
    "    plt.subplot(1, 3, i+1); imshow(cmap); plt.title(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combination to saliency map\n",
    "\n",
    "$$\\mathcal{S} = \\frac{1}{3}\\left(\\mathcal{N}\\left(\\bar{\\mathcal{I}}\\right) + \\mathcal{N}\\left(\\bar{\\mathcal{C}}\\right) + \\mathcal{N}\\left(\\bar{\\mathcal{O}}\\right) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "S = to256(sum_up([normalize(cmap) for cmap in conspicuity]) / 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "_ = imshow(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the saliency map: the winner takes it all\n",
    "\n",
    "<img src=\"ittikochniebur_model_architecture.png\" alt=\"Model architecture\" style=\"width: 60%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"ittikochniebur_wta.png\" style=\"width: 70%\" alt=\"Winner takes it all\" />\n",
    "<center><small>Fig. 3: Example of final winner takes all results.</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Results\n",
    "\n",
    "- robust in very noisy images\n",
    "- reproduces human performance, in easy and hard tasks\n",
    "- not too difficult to implement ðŸ˜Š"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python (gaze prediction)",
   "language": "python",
   "name": "gazeprediction2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
